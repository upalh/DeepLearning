"""
This script will load the feature vectors that were generated by 
word2vec_feature_generator.py and then train the net to learn a more 
distributed representation of each word. In the case of the amazon dataset,
each word corresponds to a product that a customer bought. So a sentence
would correspond to all the products that a given customer bought.

This script should be usable for any situation where the learned feature 
vectors have been created with word2vec_feature_generator.py or are
similarly formatted.

Example format of existing feature file should be:
    "customer_A2YD21XOPJ966C"       "['0790747324', '6305350221']"

TODO:
    Assumes that all the sentences will fit into memory before 
    feeding into Word2Vec. Might be a good idea to create a 
    generator to reduce memory issues.


Created on Sat Jan 25 05:44:22 2014

@author: Upal Hasan

"""

import sys
from gensim.models.word2vec import *
import matplotlib.pyplot as plt

DEFAULT_BASE_DIR = ""
    
def load_features(path_to_file, callback):
    """This function will load the features, parse them out, and return
        to the caller for processing.
        
        Args: 
            path_to_file : path to the feature vectors file
            
        Return:
            An array corresponding to the corresponding to a parsed record.
            
    """
    
    with open(path_to_file, "r") as fileHandle:
        while True:
            record = fileHandle.readline()
            if not record:
                break
            
            # call the callback function to retrieve the value of interest 
            # to return to the caller.             
            value = callback(record)
        
            yield value
    
def plot_learned_vectors(wgtMatrixPath, model):
    """Function to help us understand what was learned by plotting
        the new representations of the words in the sentences.
        
        Args:
            wgtMatrixPath : path to the weight matrix path of learned vectors.
            model : the model learned by word2vec
    """
    
    # extract out the words from the weight matrix file.
    with open(wgtMatrixPath, "r") as fileHandle:        
        vectorDim = fileHandle.readline().rstrip().split(" ")[1]
        vectorList = map(lambda x : x.rstrip().split(" ")[0], fileHandle.readlines())
        
    words = vectorList[:100]
    
    if not words or int(vectorDim) != 2:
        print "vector list empty or not proper dimension."
        return
        
    xs = []
    ys = []
    fig, ax = plt.subplots()
    
    annotations = []
    for word in words:
        try:        
            w = model[word]
            xs.append(w[0])
            ys.append(w[1])
            annotations.append(word)
        except:
            continue
        
    ax.scatter(xs, ys)
    
    # annotate the chart
    for i, txt in enumerate(annotations):
        ax.annotate(txt, (xs[i], ys[i]))
    plt.show()

def preprocess_record(line):
    """Function to parse a record that was produced by 
        word2vec_feature_generator.py. It returns the corresponding 
        key and value.
        
        Args:
            The line of record that we're processing.
            
        Returns:
            An array with the parsed elemets.
    """
    record = line.replace("'","")
    record = record.replace("\"","")            
    
    val = record.strip()
    val = val.replace("[","")
    val = val.replace("]","")

    key, value = val.split("\t")                
    valSplit = value.split(", ")                    
    
    return key, valSplit

def plot_entire_feature_vectors(model, path_to_file):
    """Function to help us understand what was learned by plotting
        the new representations of the sentences, which now is a word of
        words.
        
        Args:
            wgtMatrixPath : the features that were passed into word2vec.
            model : the model learned by word2vec
    """
    
    wgtMatrixPath = get_weight_matrix_path(path_to_file)
    with open(wgtMatrixPath, "r") as fileHandle:        
        vectorDim = fileHandle.readline().rstrip().split(" ")[1]

    keys = []
    sentences = []
    featureGenerator = load_features(path_to_file, preprocess_record)    
    for i in range(0,10):
        key, value = featureGenerator.next()                 
        
        keys.append(key)
        sentences.append(value)
        
    colorMap = [random.uniform(0,1) for sentence in sentences]
    
    if int(vectorDim) != 2:
        print "learned vectors not proper dimension."
        return
        
    xs = []
    ys = []
    colors = []
    fig, ax = plt.subplots()
    
    annotations = []
    for i, sentence in enumerate(sentences):
        for word in sentence:
            try:        
                w = model[word]
                xs.append(w[0])
                ys.append(w[1])
                annotations.append(keys[i] + ":" + word)
                colors.append(colorMap[i])
            except:
                continue
        
    ax.scatter(xs, ys, c=colors)
    
    # annotate the chart
    for i, txt in enumerate(annotations):
        ax.annotate(txt, (xs[i], ys[i]))
    plt.show()
    
    
    
def get_model_path(path_to_feature_file):
    """Function to obtain the path to the model file.
    
        Args:
            path_to_feature_file : path to the file containing all the
                features to be fed into word2vec.
        Returns:
            The path where the model file will/should reside.
    """
    return os.path.join(DEFAULT_BASE_DIR, os.path.basename(path_to_feature_file).split(".")[0] + "_model.out")    

def get_weight_matrix_path(path_to_feature_file):
    """Function to obtain the path to the weight matrix file.
    
        Args:
            path_to_feature_file : path to the file containing all the
                features to be fed into word2vec.
        Returns:
            The path where the weight matrix will/should reside.
    """    
    return os.path.join(DEFAULT_BASE_DIR, os.path.basename(path_to_feature_file).split(".")[0] + "_weight.out")    

def train_model(path_to_file):
    print "training model..."        
    time_start = time.time()
    
    # helper function to help preprocess a piece of text
    def preprocess(line):
        key, value = preprocess_record(line)        
        return value
    
    model = Word2Vec(load_features(path_to_file, preprocess), size=2, window=5, min_count=5, workers=4)
    model.save(get_model_path(path_to_file))
    model.save_word2vec_format(get_weight_matrix_path(path_to_file))    
    time_end = time.time()
    
    time_diff = time_end - time_start
    print "saved trained model..."
    print "time: " + str(time_diff/60.0) + " mins"

    return model
    
if __name__ == "__main__":
    
    if(len(sys.argv)>1):
        path_to_file = sys.argv[1]
    else:
        path_to_file = "../data/amazon/features_for_word2vec"

    DEFAULT_BASE_DIR = os.path.dirname(path_to_file)    
    #keys, features = load_features(path_to_file)    

    if os.path.exists(get_weight_matrix_path(path_to_file)):
        model = Word2Vec.load_word2vec_format(get_weight_matrix_path(path_to_file), binary=False)
        print "loaded existing model..."
    else:   
        # now dump into word2vec
        model = train_model(path_to_file)
        
    #plot_learned_vectors(get_weight_matrix_path(path_to_file), model)
    plot_entire_feature_vectors(model, path_to_file)