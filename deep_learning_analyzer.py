# -*- coding: utf-8 -*-
"""
This script will load the feature vectors that were generated by 
word2vec_feature_generator.py and then train the net to learn a more 
distributed representation of each word. In the case of the amazon dataset,
each word corresponds to a product that a customer bought. So a sentence
would correspond to all the products that a given customer bought.

This script should be usable for any situation where the learned feature 
vectors have been created with word2vec_feature_generator.py or are
similarly formatted.

Example format of existing feature file should be:
    "customer_A2YD21XOPJ966C"       "['0790747324', '6305350221']"

TODO:
    Assumes that all the sentences will fit into memory before 
    feeding into Word2Vec. Might be a good idea to create a 
    generator to reduce memory issues.


Created on Sat Jan 25 05:44:22 2014

@author: Upal Hasan

"""

import sys
from gensim.models.word2vec import *
import matplotlib.pyplot as plt

DEFAULT_BASE_DIR = ""

def load_features(path_to_file):
    """This function will load the features, parse them out, and return
        to the caller for processing.
        
        Args: 
            path_to_file : path to the feature vectors file
            
        Return:
            Two arrays. The first corresponding to the keys of a record,
            and the second corresponding to the parsed records.
            
        TODO:
            Assumes that all the sentences will fit into memory before 
            feeding into Word2Vec. Might be a good idea to create a 
            generator to reduce memory issues.
    """
    
    keys = []
    records = []
    with open(path_to_file, "r") as fileHandle:
        while True:
            record = fileHandle.readline()
            if not record:
                break
            
            # helper function to help preprocess a piece of text
            def preprocess(line):
                record = line.replace("'","")
                record = record.replace("\"","")            
                
                val = record.strip()
                val = val.replace("[","")
                val = val.replace("]","")

                return val

            # split the line after preprocessing to separate out the key
            # and value.             
            value = preprocess(record)
            key, val = value.split("\t")                
            valSplit = val.split(", ")                    
            records.append(valSplit)
            
            # now clean up any "'" or other characters in the key
            key = preprocess(key)
            keys.append(key)

    return keys, records
    
def plot_learned_vectors(wgtMatrixPath, model):
    """Function to help us understand what was learned by plotting
        the new representations of the words in the sentences.
        
        Args:
            wgtMatrixPath : path to the weight matrix path of learned vectors.
            model : the model learned by word2vec
    """
    
    # extract out the words from the weight matrix file.
    with open(wgtMatrixPath, "r") as fileHandle:        
        vectorDim = fileHandle.readline().rstrip().split(" ")[1]
        vectorList = map(lambda x : x.rstrip().split(" ")[0], fileHandle.readlines())
        
    words = vectorList[:200]
    
    if not words or int(vectorDim) != 2:
        print "vector list empty or not proper dimension."
        return
        
    xs = []
    ys = []
    fig, ax = plt.subplots()
    
    annotations = []
    for word in words:
        try:        
            w = model[word]
            xs.append(w[0])
            ys.append(w[1])
            annotations.append(word)
        except:
            continue
        
    ax.scatter(xs, ys)
    
    # annotate the chart
    for i, txt in enumerate(annotations):
        ax.annotate(txt, (xs[i], ys[i]))
    plt.show()
    
def plot_entire_feature_vectors(keys, features, model, wgtMatrixPath):
    """Function to help us understand what was learned by plotting
        the new representations of the sentences, which now is a word of
        words.
        
        Args:
            wgtMatrixPath : the features that were passed into word2vec.
            model : the model learned by word2vec
    """
    with open(wgtMatrixPath, "r") as fileHandle:        
        vectorDim = fileHandle.readline().rstrip().split(" ")[1]
    
    # extract out the words from the weight matrix file.        
    sentences = features[:100]
    colorMap = [random.uniform(0,1) for sentence in sentences]
    
    if int(vectorDim) != 2:
        print "learned vectors not proper dimension."
        return
        
    xs = []
    ys = []
    colors = []
    fig, ax = plt.subplots()
    
    annotations = []
    for i, sentence in enumerate(sentences):
        for word in sentence:
            try:        
                w = model[word]
                xs.append(w[0])
                ys.append(w[1])
                annotations.append(keys[i] + ":" + word)
                colors.append(colorMap[i])
            except:
                continue
        
    ax.scatter(xs, ys, c=colors)
    
    # annotate the chart
    for i, txt in enumerate(annotations):
        ax.annotate(txt, (xs[i], ys[i]))
    plt.show()
    
    
    
def get_model_path(path_to_feature_file):
    """Function to obtain the path to the model file.
    
        Args:
            path_to_feature_file : path to the file containing all the
                features to be fed into word2vec.
        Returns:
            The path where the model file will/should reside.
    """
    return os.path.join(DEFAULT_BASE_DIR, os.path.basename(path_to_feature_file).split(".")[0] + "_model.out")    

def get_weight_matrix_path(path_to_feature_file):
    """Function to obtain the path to the weight matrix file.
    
        Args:
            path_to_feature_file : path to the file containing all the
                features to be fed into word2vec.
        Returns:
            The path where the weight matrix will/should reside.
    """    
    return os.path.join(DEFAULT_BASE_DIR, os.path.basename(path_to_feature_file).split(".")[0] + "_weight.out")    
    
if __name__ == "__main__":
    
    if(len(sys.argv)>1):
        path_to_file = sys.argv[1]
    else:
        path_to_file = "../data/amazon/features_for_word2vec"

    DEFAULT_BASE_DIR = os.path.dirname(path_to_file)    
    keys, features = load_features(path_to_file)    

    if os.path.exists(get_weight_matrix_path(path_to_file)):
        model = Word2Vec.load_word2vec_format(get_weight_matrix_path(path_to_file), binary=False)
        print "loading existing model..."
    else:   
        # now dump into word2vec
        print "training model..."        
        time_start = time.time()
        model = Word2Vec(features, size=2, window=5, min_count=5, workers=4)
        model.save(get_model_path(path_to_file))
        model.save_word2vec_format(get_weight_matrix_path(path_to_file))    
        time_end = time.time()
        
        time_diff = time_end - time_start
        print "saved trained model..."
        print "time: " + str(time_diff/60.0) + " mins"
        
    #plot_learned_vectors(get_weight_matrix_path(path_to_file), model)
    plot_entire_feature_vectors(keys, features, model, get_weight_matrix_path(path_to_file))